\chapter*{Abstract} % l'asterisco dopo chapter serve per visualizzare il titolo senza numerazione

In questa tesi si analizza l'uso dei video egocentrici per lo studio del comportamento umano in scenari operativi, con particolare attenzione alla gestione delle interazioni tra mani e oggetti. Viene presentato AMEGO \cite{goletto2024amego}, un framework semantic-free per la strutturazione di una memoria capace di fornire informazioni basate su dati visuali-temporali.

Il lavoro prevede la realizzazione di un benchmark in un contesto industriale, utilizzando il dataset \textit{ENIGMA-51} \cite{ragusa2023enigma51}, opportunamente adattato per valutare le prestazioni del modello in un dominio differente rispetto a quello originariamente considerato \cite{Damen2021PAMI}. Le valutazioni mostrano limiti nella distinzione tra oggetti visivamente simili, sottolineando la necessità di strategie più robuste per il \textit{clustering} e l'organizzazione degli oggetti.

Nonostante queste limitazioni, AMEGO rappresenta una base solida per l'analisi dei video egocentrici, consentendo di studiare diversi aspetti che coinvolgono l'operatore umano e offrendo spunti per sviluppi futuri volti a migliorare la robustezza e la generalizzazione del modello, anche in contesti e dataset differenti.