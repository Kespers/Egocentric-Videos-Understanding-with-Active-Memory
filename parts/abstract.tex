\chapter*{Abstract} % l'asterisco dopo chapter serve per visualizzare il titolo senza numerazione

In questa tesi si analizza l'uso dei video egocentrici per lo studio del comportamento umano in scenari operativi, con particolare attenzione alla gestione delle interazioni tra mani e oggetti. Viene presentato AMEGO \cite{goletto2024amego}, un framework semantic-free per la strutturazione di una memoria capace di fornire informazioni basate su dati visuali-temporali.

Il lavoro prevede la realizzazione di un benchmark in un contesto industriale, utilizzando il dataset \textit{ENIGMA-51} \cite{ragusa2023enigma51}, opportunamente adattato per valutare le prestazioni del modello in un dominio differente rispetto a quello originariamente considerato \cite{Damen2021PAMI}. Le valutazioni mostrano limiti nella distinzione tra oggetti visivamente simili, sottolineando la necessità di strategie più robuste per il \textit{clustering} e l'organizzazione degli oggetti.

Nonostante alcune limitazioni, \textsc{AMEGO} costituisce una base solida per l'analisi dei video egocentrici, offrendo diversi spunti per sviluppi futuri volti a potenziarne le prestazioni anche in contesti differenti.