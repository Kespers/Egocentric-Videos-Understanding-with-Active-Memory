\chapter*{Conclusione}
\addcontentsline{toc}{chapter}{Conclusione}

In questa tesi abbiamo analizzato l'importanza dei video egocentrici come strumento per comprendere e modellare il comportamento umano in diversi contesti.

A tal fine, è stato introdotto AMEGO~\cite{goletto2024amego}, un framework \emph{semantic-free} per la rappresentazione di Human-Object Interaction in video egocentrici, che consente di generare una memoria attiva di oggetti e interazioni senza fare affidamento su etichette semantiche predefinite. Sono stati descritti i componenti principali del modello e il benchmark creato ad hoc, con particolare attenzione al task di \emph{query sequencing}.

Per valutare queste capacità semantic-free, è stato utilizzato il dataset industriale ENIGMA-51~\cite{ragusa2023enigma51}, opportunamente adattato per costruire un insieme di test coerente con il benchmark di \emph{AMEGO}. Si è proceduto alla creazione del benchmark esclusivamente per Q5, rispettando i vincoli temporali tra le patch relative alle diverse classi e apportando una serie di affinamenti per rendere il dataset più significativo per la valutazione.

I risultati sperimentali hanno evidenziato alcuni limiti del modello, soprattutto in contesti industriali, 
dove oggetti visivamente simili ma semanticamente differenti (ad esempio diversi tipi di cacciaviti o componenti elettrici) 
vengono talvolta considerati come appartenenti a un unico gruppo. 
Questo evidenzia la necessità di strategie più robuste per il raggruppamento degli oggetti, 
poiché la logica di AMEGO, in particolare per la query analizzata, si basa in gran parte sulla corretta assegnazione delle classi. 
La presenza di errori in questa fase ha generato un livello significativo di rumore, 
che si riflette direttamente nei risultati osservati.

Un possibile miglioramento consiste nel fine-tuning dei modelli di estrazione delle feature e di hand-object detection su dataset industriali, in modo da aumentare la capacità di distinguere oggetti visivamente simili e di cogliere dettagli a diversi livelli di precisione. 
Su un dataset industriale, tale approccio potrebbe migliorare significativamente la rilevazione e la classificazione di elementi specifici tipici di questi contesti. Tuttavia, questa modifica potrebbe ridurre la natura semantic-free del modello, favorendo l'apprendimento di classi strettamente legate al dominio industriale.

Un ulteriore miglioramento potrebbe riguardare l'uso di frame ad alta risoluzione. L'impiego delle risoluzioni originali dei dataset, sebbene più oneroso dal punto di vista computazionale, 
potrebbe favorire una migliore rilevazione dei dettagli critici degli oggetti.

Nonostante questi limiti, \emph{AMEGO} costituisce una solida base per lo studio dei video egocentrici. Il principale vincolo risiede nella forte dipendenza dai modelli di supporto, che mostrano difficoltà nel generalizzare in modo completamente indipendente dalle classi specifiche. Tale limitazione emerge in maniera più evidente nella Q5, la quale si basa quasi interamente su questi strumenti, risultando nei punteggi più bassi anche nel paper originale. Questo scenario evidenzia però il margine di miglioramento più ampio.

Per sviluppi futuri, sarebbe quindi interessante esplorare innanzitutto altre tipologie di query, considerando anche l'eventuale utilizzo di dataset alternativi. Sarebbe inoltre utile valutare il comportamento del modello utilizzando strumenti class-agnostic differenti, poiché costituiscono la struttura portante del modello e potrebbero influenzarne significativamente le prestazioni.


